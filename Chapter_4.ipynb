{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Глава 4 Выделение и использование лингвистических признаков"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лингвистические признаки -- это, например, теги частей речи, синтаксические\n",
    "зависимости и именованне сущности. \n",
    "\n",
    "<b>В этой главе</b> вы научитесь выделять и генерировать текст на основе тегов частей речи и синтаксических зави- симостей, что позволит создавать отвечающие на вопросы чат-боты,\n",
    "находить в тексте конкретные фразы и многое другое."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Выделение и генерация текста с помощью тегов частей речи</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ru_core_news_lg\n",
    "import spacy as sp\n",
    "import sys\n",
    "\n",
    "from spacy.symbols import ORTH, LEMMA\n",
    "from IPython.display import Image\n",
    "from spacy.tokens.doc import Doc\n",
    "from spacy.vocab import Vocab\n",
    "\n",
    "from spacy import displacy\n",
    "from IPython.display import Image\n",
    "\n",
    "nlp = sp.load('ru_core_news_lg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Для начала выделим из токенов признаки общих частей речи и увидим, как spaCy распознает различные части речи:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фильм      NOUN       noun      \n",
      "собрал     VERB       verb      \n",
      "$          SYM        symbol    \n",
      "1.5        NUM        numeral   \n",
      "миллиона   NOUN       noun      \n",
      "в          ADP        adposition\n",
      "2019       ADJ        adjective \n",
      "году       NOUN       noun      \n",
      ".          PUNCT      punctuation\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Фильм собрал $1.5 миллиона в 2019 году.\")\n",
    "for token in doc:\n",
    "    print('{0:10s} {1:10s} {2:10s}'.format(token.text, token.pos_, sp.explain(token.pos_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text       pos_       dep_       explain   \n",
      "_____________________________________________\n",
      "Фильм      NOUN       nsubj      noun      \n",
      "собрал     VERB       ROOT       verb      \n",
      "$          SYM        obj        symbol    \n",
      "1.5        NUM        nummod     numeral   \n",
      "миллиона   NOUN       nummod:gov noun      \n",
      "в          ADP        case       adposition\n",
      "2019       ADJ        amod       adjective \n",
      "году       NOUN       obl        noun      \n",
      ".          PUNCT      punct      punctuation\n"
     ]
    }
   ],
   "source": [
    "print('{0:10s} {1:10s} {2:10s} {3:10s}'.format('text', 'pos_', 'dep_', 'explain'))\n",
    "print('_'* 45)\n",
    "for token in doc:\n",
    "    print('{0:10s} {1:10s} {2:10s} {3:10s}'.format(token.text, token.pos_, token.dep_, sp.explain(token.tag_)))\n",
    "\n",
    "# ВОПРОС, почему совпадают pos_ and tag_??? Не знаю, но метод dep_ отлично заменяет его"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сравним теги общих и уточненных частей речи для того же предложения,"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Выделение описаний денежных сумм</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$1.5 миллиона\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Фильм собрал $1.5 миллиона в 2019 году.\")\n",
    "\n",
    "phrase = ''\n",
    "for token in doc:\n",
    "    if token.tag_ == 'SYM':\n",
    "        phrase = token.text\n",
    "        i = token.i + 1\n",
    "        while doc[i].dep_ == 'nummod' or doc[i].dep_ == 'nummod:gov':\n",
    "            phrase += doc[i].text + ' '\n",
    "            i += 1\n",
    "        break\n",
    "phrase = phrase[:-1]\n",
    "print(phrase)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Преобразование утвердительных высказываний в вопросительные</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text       pos_       dep_       explain   \n",
      "_____________________________________________\n",
      "Я          PRON       nsubj      pronoun   \n",
      "хочу       VERB       ROOT       verb      \n",
      "купить     VERB       xcomp      verb      \n",
      "то         DET        det        determiner\n",
      "свежее     ADJ        amod       adjective \n",
      "яблоко     NOUN       obj        noun      \n",
      ".          PUNCT      punct      punctuation\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Я хочу купить то свежее яблоко.')\n",
    "\n",
    "print('{0:10s} {1:10s} {2:10s} {3:10s}'.format('text', 'pos_', 'dep_', 'explain'))\n",
    "print('_'* 45)\n",
    "for token in doc:\n",
    "    print('{0:10s} {1:10s} {2:10s} {3:10s}'.format(token.text, token.pos_, token.dep_, sp.explain(token.pos_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/picture_3.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"images/picture_3.png\", width=500, height=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как эта схема подхожит только для англйиского языка, то мы отойдем от нее и адаптируем под русский язык."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я хочу купить то свежее яблоко.\n",
      "Вы хочу купить то свежее яблоко.\n",
      "Вы хочу купить это свежее яблоко.\n",
      "Вы хотите купить это свежее яблоко.\n",
      "Вы хотите купить это свежее яблоко?\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Я хочу купить то свежее яблоко.')\n",
    "print(doc)\n",
    "\n",
    "sent = ''\n",
    "for i, token in enumerate(doc):\n",
    "    if token.dep_ == 'nsubj' and token.text == 'Я':\n",
    "        sent = doc[:i].text + 'Вы ' + doc[i + 1:].text\n",
    "        break\n",
    "print(sent)\n",
    "\n",
    "# К этому моменту предложение должно выглядеть так:\n",
    "# вы хочу купить свежее яблоко.\n",
    "\n",
    "doc = nlp(sent)\n",
    "for i, token in enumerate(doc):\n",
    "    if token.dep_ == 'det' and token.text == 'то':\n",
    "        sent = doc[:i].text + ' это ' + doc[i + 1:].text\n",
    "        break\n",
    "print(sent)\n",
    "# К этому моменту предложение должно выглядеть так:\n",
    "# Вы хочу купить это свежее яблоко.\n",
    "\n",
    "doc = nlp(sent)\n",
    "for i, token in enumerate(doc):\n",
    "    if token.dep_ == 'ROOT':\n",
    "        sent = doc[:i].text + ' хотите ' + doc[i + 1:].text\n",
    "        break\n",
    "print(sent)\n",
    "\n",
    "# К этому моменту предложение должно выглядеть так:\n",
    "# Вы хотите купить это свежее яблоко.\n",
    "doc = nlp(sent)\n",
    "sent = doc[:len(doc)-1].text + '?'\n",
    "\n",
    "# Наконец, мы получаем: Вы хотите купить это свежее яблоко?\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/picture_4.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"images/picture_4.png\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я хочу купить то свежее яблоко.\n",
      " Вы хочу купить то свежее яблоко.\n"
     ]
    }
   ],
   "source": [
    "def replace_token(doc, tok_dep, tok_text, repl):\n",
    "    sent = ''\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.dep_ == tok_dep and token.text == tok_text:\n",
    "            sent = doc[:i].text + ' ' + repl + ' ' + doc[i + 1:].text\n",
    "            break\n",
    "    return nlp(sent)\n",
    "    \n",
    "doc = nlp(u'Я хочу купить то свежее яблоко.')  \n",
    "print(doc)\n",
    "doc = replace_token(doc, 'nsubj', 'Я', 'Вы') \n",
    "print(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Использование меток синтаксических зависимостей при обработке текста\n",
    "\n",
    "Различаем подлежащие и дополнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/picture_5.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"images/picture_5.png\", width=500, height=300)\n",
    "# ВАЖНО - в русском tag_ и pos_ одно и то же, то есть нет уточнений частей речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/picture.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dep_\n",
    "Image(url=\"images/picture.png\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text            pos_       dep_       tag_       explain   \n",
      "_______________________________________________________\n",
      "Таня            PROPN      nsubj      PROPN      nominal subject\n",
      "выучила         VERB       ROOT       VERB       root      \n",
      "все             DET        det        DET        determiner\n",
      "теоремы         NOUN       obj        NOUN       object    \n",
      "по              ADP        case       ADP        case marking\n",
      "математическому ADJ        amod       ADJ        adjectival modifier\n",
      "анализу         NOUN       nmod       NOUN       modifier of nominal\n",
      "вчера           ADV        advmod     ADV        adverbial modifier\n",
      "и               CCONJ      cc         CCONJ      coordinating conjunction\n",
      "объяснила       VERB       conj       VERB       conjunct  \n",
      "их              PRON       obj        PRON       object    \n",
      "Коле            PROPN      iobj       PROPN      indirect object\n",
      ".               PUNCT      punct      PUNCT      punctuation\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Таня выучила все теоремы по математическому анализу вчера и объяснила их Коле.')\n",
    "\n",
    "# dep_ == метки зависимости\n",
    "print('{0:15s} {1:10s} {2:10s} {3:10s} {4:10s}'.format('text', 'pos_', 'dep_', 'tag_', 'explain'))\n",
    "print('_'* 55)\n",
    "for token in doc:\n",
    "    print('{0:15s} {1:10s} {2:10s} {3:10s} {4:10s}'.format(token.text, token.pos_, token.dep_, token.tag_, sp.explain(token.dep_)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имена \"Таня\" и \"Коле\" совпадают в pos_, но отличаются в dep_\n",
    "text            pos_       dep_       tag_       explain   \n",
    "____________________________________________________________\n",
    "Таня            PROPN      nsubj      PROPN      nominal subject   \n",
    "Коле            PROPN      iobj       PROPN      indirect object"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выясняем, какой вопрос должен задать чат-бот\n",
    "\n",
    "Иногда для извлечения необходимой информации приходится обходить дерево зависимостей предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/picture_6.png\" width=\"300\" height=\"100\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"images/picture_6.png\", width=300, height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/picture_7.png\" width=\"500\" height=\"150\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"images/picture_7.png\", width=500, height=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возвращение прямого дополнения (по книжке это dobj, однако в русском spacy есть только obj, iobj)\n",
    "def find_chunk(doc):\n",
    "    chunk = ''\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.dep_ == 'obj':\n",
    "            shift = len([w for w in token.children])\n",
    "            #print([w for w in token.children])\n",
    "            chunk = doc[i-shift:i+1]\n",
    "            break\n",
    "    return chunk\n",
    "\n",
    "def determine_question_type(chunk):\n",
    "    question_type = 'yesno'\n",
    "    for token in chunk:\n",
    "        # ищет модификатор прилагательного (пример: \"красный\" шар)\n",
    "        if token.dep_ == 'amod':\n",
    "            question_type = 'info'\n",
    "    return question_type\n",
    "\n",
    "\n",
    "def generate_question(doc, question_type):\n",
    "    sent = ''\n",
    "\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.dep_ == 'nsubj' and token.text == 'Я':\n",
    "            sent = doc[:i].text + 'Вы ' + doc[i + 1:].text\n",
    "            break\n",
    "        \n",
    "    doc = nlp(sent)\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.dep_ == 'ROOT':\n",
    "            sent = doc[:i].text + ' хотите ' + doc[i + 1:].text\n",
    "            break\n",
    "        \n",
    "    doc = nlp(sent)\n",
    "    if question_type == 'info':\n",
    "        for i, token in enumerate(doc):\n",
    "            if token.dep_ == 'obj':\n",
    "                sent = 'Хотите ли ' + doc[:i].text  +  doc[i+1:].text\n",
    "                break\n",
    "    if question_type == 'yesno':\n",
    "        for i, token in enumerate(doc):\n",
    "            if token.dep_ == 'obj':\n",
    "                sent = doc[:i-1].text + ' хотите зеленое ' + doc[i:].text\n",
    "                break\n",
    "\n",
    "    doc = nlp(sent)\n",
    "    sent = doc[:len(doc)-1].text + '?'        \n",
    "\n",
    "    return sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text            pos_       dep_       tag_       explain   \n",
      "_______________________________________________________\n",
      "Я               PRON       nsubj      PRON       nominal subject\n",
      "хочу            VERB       ROOT       VERB       root      \n",
      "грушу           NOUN       obj        NOUN       object    \n",
      ".               PUNCT      punct      PUNCT      punctuation\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Я хочу грушу.\")\n",
    "# dep_ == метки зависимости\n",
    "print('{0:15s} {1:10s} {2:10s} {3:10s} {4:10s}'.format('text', 'pos_', 'dep_', 'tag_', 'explain'))\n",
    "print('_'* 55)\n",
    "for token in doc:\n",
    "    print('{0:15s} {1:10s} {2:10s} {3:10s} {4:10s}'.format(token.text, token.pos_, token.dep_, token.tag_, sp.explain(token.dep_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "грушу\n"
     ]
    }
   ],
   "source": [
    "# Возвращение первого прямого дополнения \n",
    "print(find_chunk(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вы хотите зеленое грушу?\n"
     ]
    }
   ],
   "source": [
    "# пробуем использовать модель чат бота\n",
    "chunk = find_chunk(doc)\n",
    "if str(chunk) == '':\n",
    "  print('The sentence does not contain a direct object.')\n",
    "  sys.exit()\n",
    "question_type = determine_question_type(chunk)\n",
    "question = generate_question(doc, question_type)\n",
    "print(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
