{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Глава 5. Работа с векторами слов\n",
    "Узнаю - применение алгоритмов машинного обучения для генерации векторов слов, метод подобия (определяет близость смыслов объектов- контейнеров путем сравнения соответствующих векторов слов). Как повысить эффективность операций, в частности выбор ключевых слов, с помощью предварительной обработки?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ru_core_news_lg\n",
    "import spacy as sp\n",
    "import sys\n",
    "\n",
    "from spacy.symbols import ORTH, LEMMA\n",
    "from IPython.display import Image\n",
    "from spacy.tokens.doc import Doc\n",
    "from spacy.vocab import Vocab\n",
    "\n",
    "from spacy import displacy\n",
    "from IPython.display import Image\n",
    "\n",
    "nlp = sp.load('ru_core_news_lg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод similarity\n",
    "Результат близкий к 1 показывает, что фразы или слова очень близки (диапазон значений степени подобия от 0 до 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Я хочу спать в кроватке.  |  спать в кроватке : 0.9451089102124649\n",
      "в кроватке  |  на диване : 0.4528334140777588\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Я хочу спать в кроватке.\")\n",
    "doc2 = nlp(u\"Я хочу спать на диване.\")\n",
    "\n",
    "# покажем близость фраз \"Я хочу спать в кроватке\" и \"спать в кроватке\"\n",
    "print(doc.similarity(doc))\n",
    "\n",
    "print(doc, \" | \", doc[2:5], \":\",  doc.similarity(doc[2:5]))\n",
    "print(doc[3:5], \" | \", doc2[3:5], \":\",  doc[3:5].similarity(doc2[3:5]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cравниваем объект Token \"кроватке\" с объектом Span, содержащим один токен \"диване\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4176931083202362\n"
     ]
    }
   ],
   "source": [
    "token = doc[4:5][0]\n",
    "print(token.similarity(doc2[4:5]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Использование сторонних пакетов векторов слов\n",
    "Возникли проблемки с заргрузкой пакетика"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравнение объектов spaCy. Применение семантического подобия для задач категоризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я хочу купить эту прекрасную книгу в конце недели.\n",
      "similarity to фрукты is 0.18718963861465454 \n",
      "\n",
      "Продажи апельсинов выросли за последний год.\n",
      "similarity to фрукты is 0.26642706990242004 \n",
      "\n",
      "Как много вы знаете об этом типе деревьев?\n",
      "similarity to фрукты is 0.15825019776821136 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Я хочу купить эту прекрасную книгу в конце недели. Продажи апельсинов выросли за последний год. Как много вы знаете об этом типе деревьев?\")\n",
    "token = nlp(u'фрукты')[0]\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "    print('similarity to', token.text, 'is', token.similarity(sent),'\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выделение существительных как шаг предварительной обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['книгу', 'конце', 'недели']\n",
      "['Продажи', 'апельсинов', 'год']\n",
      "['типе', 'деревьев']\n",
      "{0: 0.11895324898625022, 1: 0.3911665157072323, 2: 0.11317716145060874}\n"
     ]
    }
   ],
   "source": [
    "simil = {}\n",
    "\n",
    "for i, sent in enumerate(doc.sents):\n",
    "    noun_span_list = [sent[j].text for j in range(len(sent)) if sent[j].pos_ == 'NOUN']\n",
    "    print(noun_span_list)\n",
    "    noun_span_str = ' '.join(noun_span_list)\n",
    "    noun_span_doc = nlp(noun_span_str)\n",
    "    simil.update({i:token.similarity(noun_span_doc)})\n",
    "\n",
    "print(simil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/picture_8.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"images/picture_8.png\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['книгу', 'конце', 'недели']\n",
      "[0.06992303473157861, 0.0128732583159894, 0.16338935322537068]\n",
      "['Продажи', 'апельсинов', 'год']\n",
      "[0.0, 0.4235835941789032, 0.11856940699250682]\n",
      "['типе', 'деревьев']\n",
      "[0.07038050812929242, 0.20813423873229375]\n",
      "{0: 0.16338935322537068, 1: 0.4235835941789032, 2: 0.20813423873229375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/8zxgwvj510zc_3b1s0jbh5180000gn/T/ipykernel_72179/1997239711.py:10: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  dist.append(abs((token.similarity(nlp(chunk)))))\n"
     ]
    }
   ],
   "source": [
    "max_similarity = {}\n",
    "dist = []\n",
    "\n",
    "for i, sent in enumerate(doc.sents):\n",
    "    noun_span_list = [sent[j].text for j in range(len(sent)) if sent[j].pos_ == 'NOUN']\n",
    "    print(noun_span_list)\n",
    "    \n",
    "    dist = []\n",
    "    for j, chunk in enumerate(noun_span_list):\n",
    "        dist.append(abs((token.similarity(nlp(chunk)))))\n",
    "    print(dist)\n",
    "\n",
    "    max_similarity.update({i:max(dist)})\n",
    "\n",
    "print(max_similarity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выделение и сравнение именованных сущностей\n",
    "метод отлично работает для английского языка, но для русского - ясно понятно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(u\"Волгоград очень красивый город и если вы хотите его увидеть, то вам обязательно стоит посетить его. Это город который не оставит равнодушным никого, а так же здесь можно встретить очень много интересных людей.\")\n",
    "doc2 = nlp(u\"Москва выглядит чудесно. Я не могу сказать, что это такое волшебное место, но точно, что оно очень красивое. Мне нравится здесь. И я хочу остаться здесь в Москве надолго.\")\n",
    "doc3 = nlp(u\"Река Волга самая длинная в Европе. Длина реки составляет 3550 километров. В среднем течении она образует самую большую дельту в мире.\")\n",
    "docs = [doc1, doc2, doc3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Волгоград']\n",
      "['Москва', 'Москве']\n",
      "['Европе']\n"
     ]
    }
   ],
   "source": [
    "spans = {}\n",
    "for j,doc in enumerate(docs):\n",
    "    named_entity_span = [doc[i].text for i in range(len(doc)) if doc[i].ent_type != 0]\n",
    "    print(named_entity_span)\n",
    "    named_entity_span = ' '.join(named_entity_span)\n",
    "    named_entity_span = nlp(named_entity_span)\n",
    "    spans.update({j:named_entity_span})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc1 is similar to doc2: 0.0\n",
      "doc1 is similar to doc3: 0.0\n",
      "doc2 is similar to doc3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/8zxgwvj510zc_3b1s0jbh5180000gn/T/ipykernel_72179/653064147.py:1: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  print('doc1 is similar to doc2:',spans[0].similarity(spans[1]))\n",
      "/var/folders/c9/8zxgwvj510zc_3b1s0jbh5180000gn/T/ipykernel_72179/653064147.py:2: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  print('doc1 is similar to doc3:',spans[0].similarity(spans[2]))\n",
      "/var/folders/c9/8zxgwvj510zc_3b1s0jbh5180000gn/T/ipykernel_72179/653064147.py:3: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  print('doc2 is similar to doc3:',spans[1].similarity(spans[2]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/8zxgwvj510zc_3b1s0jbh5180000gn/T/ipykernel_72179/653064147.py:7: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  print(token1.similarity(token2))\n"
     ]
    }
   ],
   "source": [
    "print('doc1 is similar to doc2:',spans[0].similarity(spans[1]))\n",
    "print('doc1 is similar to doc3:',spans[0].similarity(spans[2]))\n",
    "print('doc2 is similar to doc3:',spans[1].similarity(spans[2]))\n",
    "\n",
    "token1 = nlp(u\"Настя\")\n",
    "token2 = nlp(u\"Анастасия\")\n",
    "print(token1.similarity(token2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
