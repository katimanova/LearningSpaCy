{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Глава 10. Обучение моделей**\n",
    "\n",
    "В главе 1 вы узнали, что библиотека spaCy включает в себя статистические нейросетевые модели, предобученные для распознавания именованных сущностей, частеречной разметки, синтаксического разбора зависимостей и предсказания семантического подобия.\n",
    "\n",
    "Но никто не ограничивает нас одними лишь предобученными готовыми моделями. При желании можно обучить модель на собственных примерах, настроив компоненты ее конвейера под потребности своего приложения.\n",
    "\n",
    "\n",
    "В этой главе обсуждаются вопросы обучения средств распознавания именованных сущностей и синтаксического разбора зависимостей — компонентов конвейера. Их чаще всего приходится настраивать так, чтобы модель отвечала требованиям конкретного сценария использования. \n",
    "\n",
    "Кроме того, вы узнаете, как сохранить настроенный компонент конвейера на диск для последующей загрузки его в другом сценарии или модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ru_core_news_lg\n",
    "import spacy as sp\n",
    "import sys\n",
    "\n",
    "from spacy.symbols import ORTH, LEMMA\n",
    "from IPython.display import Image\n",
    "from spacy.tokens.doc import Doc\n",
    "from spacy.vocab import Vocab\n",
    "\n",
    "from spacy import displacy\n",
    "from IPython.display import Image\n",
    "\n",
    "from function import *\n",
    "\n",
    "nlp = sp.load('ru_core_news_lg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Обучение компонента конвейера модели**\n",
    "Для настройки под цели и задачи конкретного приложения обучать модель с нуля приходится редко. Обычно можно воспользоваться уже существующей моделью и обновить только определенный компонент конвейера\n",
    "\n",
    "Этот процесс, как правило, состоит из двух шагов: подготовки обучающих примеров данных (набора предложений с лингвисти- ческой разметкой, подходящих для обучения модели) и передачи их нужному компоненту конвейера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/picture_17.png\" width=\"550\" height=\"450\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"images/picture_17.png\", width=550, height=450)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время обучения библиотека spaCy корректирует весовые коэффициенты модели на основе обучающих примеров данных, стремясь минимизировать погрешность, еще называемую **потерями/функцией потерь (loss)**, предсказаний, выполняемых моделью. Проще говоря, алгоритм вычисляет соотношение токена и метки, определяя вероятность того, что данному токену следует присвоить именно эту метку.\n",
    "\n",
    "На практике для полноценного обучения компонента модели могут понадобиться сотни или даже тысячи обучающих примеров данных.\n",
    "\n",
    "**! Прежде чем обучать определенный компонент, необходимо временно отключить все остальные компоненты конвейера модели, чтобы защитить их от ненужных изменений.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Обучение средства распознавания именованных сущностей**\n",
    "\n",
    "Представьте, что вы разрабатываете чат-бот для такси, который, само собой, должен правильно распознавать все географические названия в городе и окрестностях. Для этого необходимо обновить систему рас- познавания именованных сущностей модели на основе своих примеров данных. Например, слово Solnce, обозначающее название микрорайона в городе, система должна определять как географическую сущность. В следующих разделах описан способ решения этой задачи.\n",
    "\n",
    "#### **Определяем, нужно ли обучать средство распознавания именованных сущностей**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Солнце LOC\n",
      "Non-GPE locations, mountain ranges, bodies of water\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Не могли бы вы заехать за мной в Солнце?')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "print(sp.explain('LOC'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что средство распознавания именованных сущностей классифицировало Solnce как местоположение, не являющееся сущно- стью типа **GPE**. Значит, чтобы Solnce распознавалось как сущность типа GPE, средство распознавания нужно обновить. О том, как это сделать, поговорим в следующих разделах.\n",
    "\n",
    "Однако GPE - не встречается в русской модели spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Создание обучающих примеров данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exams = [\n",
    "    ('Не могли бы вы прислать такси в Солнце?', {'entities': [(32, 38, 'GPE')] }),\n",
    "    ('Существует ли фиксированный тариф на проезд в аэропорт из Солнца?', {'entities': [(58, 64, 'GPE')]}),\n",
    "    ('Сколько времени сейчас занимает ожидание такси?', {'entities': []})\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Автоматизация процесса создания примеров данных**\n",
    "\n",
    "Вы уже могли убедиться в том, что создание обучающего набора данных вручную требует немало времени. К тому же оно чревато ошибками, особенно если требуется обработать сотни или тысячи высказываний. Автоматизировать этот утомительный процесс можно с помощью следующего сценария, который быстро создает набор обучающих примеров данных на основе заданного текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Не могли бы вы прислать такси в Даунтон?', {'entities': [(32, 39, 'LOC')]}),\n",
       " ('Мне нужно попасть в Москву.', {'entities': [(20, 26, 'LOC')]}),\n",
       " ('Не могли бы вы прислать такси на час позже?', {'entities': []})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'Не могли бы вы прислать такси в Даунтон? Мне нужно попасть в Москву. Не могли бы вы прислать такси на час позже?')\n",
    "\n",
    "#f = open(\"test.txt\",\"rb\")\n",
    "# #contents =f.read()\n",
    "#doc = nlp(contents.decode('utf8'))\n",
    "train_exams = []\n",
    "districts = ['Солнце', 'Гринвальд', 'Даунтон'] \n",
    "\n",
    "for sent in doc.sents:\n",
    "    entities = []\n",
    "    for token in sent:\n",
    "        if token.ent_type != 0:\n",
    "            start = token.idx - sent.start_char\n",
    "            if token.text in districts:\n",
    "                entity = (start, start + len(token), 'LOC')\n",
    "            else:\n",
    "                entity = (start, start + len(token), token.ent_type_)\n",
    "            entities.append(entity)\n",
    "\n",
    "    tpl = (sent.text, {'entities': entities})\n",
    "    train_exams.append(tpl)\n",
    "\n",
    "train_exams"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для улучшения результатов обучения в обучающий набор необходимо включать не только примеры прочих типов сущностей, но и примеры, не содержащие никаких сущностей. В подразделе «Процесс обучения» на с. 203 обо всем этом рассказано более подробно."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Отключение лишних компонентов конвейера**\n",
    "Документация spaCy рекомендует перед запуском процесса обуче- ния конкретного компонента конвейера отключать все прочие его компоненты, чтобы модифицировать только тот компонент, который необходимо обновить. \n",
    "\n",
    "Следующий код отключает все компоненты конвейера, за исключением средства распознавания именованных сущностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "nlp.meta['pipeline']\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "\n",
    "#print(nlp.disable_pipes(*other_pipes))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно начинать обучение средства распознавания именованных сущностей нахождению новых сущностей, описанных в обучающих примерах данных."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Процесс обучения**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий код иллюстрирует обработку обучающих примеров данных по отдельным порциям (так называемым батчам). При этом обучающие примеры демонстрируются модели в различных представлениях во избежание усвоения ненужных обобщений, которые могут встретиться в обучающем корпусе.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно было бы создать оптимизатор с помощью метода **nlp.begin_ training()**, но он очищает список типов сущностей. А в этом примере при обновлении уже существующей модели нежелательно, чтобы она «забывала» имеющиеся типы сущностей, поэтому воспользуемся методом **nlp.entity.create_optimizer()**, который создает оптимиза- тор для средства распознавания именованных сущностей без потери имеющегося набора типов сущностей."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим метод entity.create_optimizer() не работает для Русского языка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  \\noptimizer = nlp.entity.create_optimizer()\\n\\nfor i in range(25):\\n    random.shuffle(train_exams)\\n    max_batch_size = 3\\n    batch_size = compounding(2.0, max_batch_size, 1.001)\\n    batches = minibatch(train_exams, size=batch_size)\\n    for batch in batches:\\n        texts, annotations = zip(*batch)\\n    \\n        nlp.update(texts, annotations, sgd=optimizer)\\n\\n    ner = nlp.get_pipe('ner')\\n    ner.to_disk('/Users/anastasia/ner')\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "'''  \n",
    "optimizer = nlp.entity.create_optimizer()\n",
    "\n",
    "for i in range(25):\n",
    "    random.shuffle(train_exams)\n",
    "    max_batch_size = 3\n",
    "    batch_size = compounding(2.0, max_batch_size, 1.001)\n",
    "    batches = minibatch(train_exams, size=batch_size)\n",
    "    for batch in batches:\n",
    "        texts, annotations = zip(*batch)\n",
    "    \n",
    "        nlp.update(texts, annotations, sgd=optimizer)\n",
    "\n",
    "    ner = nlp.get_pipe('ner')\n",
    "    ner.to_disk('/Users/anastasia/ner')\n",
    "'''\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После загрузки и обучение новая модель должна распозновать соответсвтующие именнованые сущности"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Создание нового синтаксического анализатора**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующих разделах рассмотрим, как создать свой синтаксический анализатор, приспособленный для конкретной задачи. В частности, обучим анализатор, способный раскрывать в предложении семантические отношения, а не синтаксические зависимости. Семантические отношения (semantic relations) складываются в предложении между значениями слов и фраз."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Понимание входного текста с помощью нестандартного синтаксического разбора зависимостей**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представьте, что чат-бот должен понимать запросы пользователя, сформулированные на английском языке, и преобразовывать их в SQL-запросы **для передачи в базу данных**. Для этого он производит синтаксический разбор, выделяя смысл и разрезая входной текст на части, которые затем используются при формировании запроса к базе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Найти', 'ROOT', 'Найти'), ('высокооплачиваемую', 'amod', 'работу'), ('работу', 'obj', 'Найти'), ('без', 'case', 'опыта'), ('опыта', 'obl', 'Найти'), ('работы', 'nmod', 'опыта'), ('.', 'punct', 'Найти')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Найти высокооплачиваемую работу без опыта работы.')\n",
    "print([(t.text, t.dep_, t.head.text) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text       pos_       dep_         tag_      \n",
      "_______________________________________________________\n",
      "Найти      VERB       ROOT         VERB      \n",
      "высокооплачиваемую ADJ        amod         ADJ       \n",
      "работу     NOUN       obj          NOUN      \n",
      "без        ADP        case         ADP       \n",
      "опыта      NOUN       obl          NOUN      \n",
      "работы     NOUN       nmod         NOUN      \n",
      ".          PUNCT      punct        PUNCT     \n",
      "_______________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nice_print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"ru\" id=\"3141ea0fbca643e7b1cbcc7b15ce1ef8-0\" class=\"displacy\" width=\"1100\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Найти</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">высокооплачиваемую</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">работу</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">без</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">опыта</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">работы.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3141ea0fbca643e7b1cbcc7b15ce1ef8-0-0\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3141ea0fbca643e7b1cbcc7b15ce1ef8-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3141ea0fbca643e7b1cbcc7b15ce1ef8-0-1\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3141ea0fbca643e7b1cbcc7b15ce1ef8-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,266.5 L403.0,254.5 387.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3141ea0fbca643e7b1cbcc7b15ce1ef8-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3141ea0fbca643e7b1cbcc7b15ce1ef8-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3141ea0fbca643e7b1cbcc7b15ce1ef8-0-3\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3141ea0fbca643e7b1cbcc7b15ce1ef8-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,266.5 L758.0,254.5 742.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3141ea0fbca643e7b1cbcc7b15ce1ef8-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3141ea0fbca643e7b1cbcc7b15ce1ef8-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удовлетворения требований приложения разметку придется по- менять так, чтобы упростить задачу генерации запросов базы данных. Поэтому необходимо реализовать нестандартный синтаксический анализатор, который отображал бы семантические отношения, а не синтаксические зависимости. В данном случае нам нужна дуга между словами **работа** и **опыт**. В следующих разделах описано, как это сделать."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Выбор используемых типов семантических отношений**\n",
    "\n",
    "\n",
    "Для соответствия требованиям семантики в список необходимо до- бавить еще один тип — ACTIVITY. Он послужит меткой для слова job в нашем примере предложения. (Хотя и исходного множества типов отношений может быть достаточно, ведь работа обычно ассоциируется с конкретным местом, для которого можно использовать тип PLACE.)\n",
    "\n",
    "#### **Создание обучающих примеров данных**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не совсем понятно как использовать для русского - массив данных heads???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA = [\n",
    "    ('найти высокооплачиваемую работу без опыта', {\n",
    "        'heads': [0, 2, 0, 4, 0],\n",
    "        'deps': ['ROOT', 'obj', 'ROOT', 'obl', 'ROOT']\n",
    "    }),\n",
    "    ('найти хорошие занятия по тренировкам рядом с домом', {\n",
    "        'heads': [0, 2, 0, 4, 2, 0, 7, 5],\n",
    "        'deps': ['ROOT', 'obj', 'ROOT', 'nmod', 'obj', 'ROOT', 'obl', 'advmod']\n",
    "}) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 0, 4, 2, 0, 7, 5]\n",
      "['ROOT', 'obj', 'ROOT', 'nmod', 'obj', 'ROOT', 'obl', 'advmod']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"ru\" id=\"1957be1f53a34ee78ecf67a496723f63-0\" class=\"displacy\" width=\"1450\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">найти</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">хорошие</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">занятия</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">по</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">тренировкам</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">рядом</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">с</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">домом</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1957be1f53a34ee78ecf67a496723f63-0-0\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1957be1f53a34ee78ecf67a496723f63-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1957be1f53a34ee78ecf67a496723f63-0-1\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1957be1f53a34ee78ecf67a496723f63-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,266.5 L403.0,254.5 387.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1957be1f53a34ee78ecf67a496723f63-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1957be1f53a34ee78ecf67a496723f63-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1957be1f53a34ee78ecf67a496723f63-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1957be1f53a34ee78ecf67a496723f63-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1957be1f53a34ee78ecf67a496723f63-0-4\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1957be1f53a34ee78ecf67a496723f63-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,266.5 L933.0,254.5 917.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1957be1f53a34ee78ecf67a496723f63-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1957be1f53a34ee78ecf67a496723f63-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1957be1f53a34ee78ecf67a496723f63-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1957be1f53a34ee78ecf67a496723f63-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text       pos_       dep_         tag_      \n",
      "_______________________________________________________\n",
      "найти      VERB       ROOT         VERB      \n",
      "хорошие    ADJ        amod         ADJ       \n",
      "занятия    NOUN       obj          NOUN      \n",
      "по         ADP        case         ADP       \n",
      "тренировкам NOUN       nmod         NOUN      \n",
      "рядом      ADV        advmod       ADV       \n",
      "с          ADP        case         ADP       \n",
      "домом      NOUN       obl          NOUN      \n",
      "_______________________________________________________\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'найти хорошие занятия по тренировкам рядом с домом')\n",
    "heads = []\n",
    "deps = []\n",
    "for token in doc:\n",
    "    heads.append(token.head.i)\n",
    "    deps.append(token.head.dep_)\n",
    "print(heads)\n",
    "print(deps)\n",
    "\n",
    "displacy.render(doc, style='dep')\n",
    "nice_print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ROOT', 'acl', 'acl:relcl', 'advcl', 'advmod', 'amod', 'appos', 'aux', 'aux:pass', 'case', 'cc', 'ccomp', 'compound', 'conj', 'cop', 'csubj', 'csubj:pass', 'dep', 'det', 'discourse', 'expl', 'fixed', 'flat', 'flat:foreign', 'flat:name', 'iobj', 'list', 'mark', 'nmod', 'nsubj', 'nsubj:pass', 'nummod', 'nummod:entity', 'nummod:gov', 'obj', 'obl', 'obl:agent', 'orphan', 'parataxis', 'punct', 'xcomp']\n"
     ]
    }
   ],
   "source": [
    "parser_lst = nlp.pipe_labels['parser']\n",
    "\n",
    "print(parser_lst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Обучение анализатора**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training import Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = nlp(\"найти высокооплачиваемую работу без опыта\")\n",
    "example = Example.from_dict(d, {\"heads\": [0, 2, 0, 4, 0], 'deps': ['ROOT', 'obj', 'ROOT', 'obl', 'ROOT']})\n",
    "ex = [example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('L-dep', 0, 9000.0)\n",
      "('R-dep', 0, 9000.0)\n",
      "('B-ROOT', 0, 9000.0)\n",
      "('Gold sent starts?', 1, 0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E1031] Could not find gold transition - see logs above.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/anastasia/Desktop/ML/Learn_ML/Chapter_10.ipynb Ячейка 40\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/ML/Learn_ML/Chapter_10.ipynb#X54sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/ML/Learn_ML/Chapter_10.ipynb#X54sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     random\u001b[39m.\u001b[39mshuffle(TRAINING_DATA)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/anastasia/Desktop/ML/Learn_ML/Chapter_10.ipynb#X54sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     nlp\u001b[39m.\u001b[39;49mupdate(ex, sgd\u001b[39m=\u001b[39;49moptimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/ML/Learn_ML/Chapter_10.ipynb#X54sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m parser\u001b[39m.\u001b[39mto_disk(\u001b[39m'\u001b[39m\u001b[39m/Users/anastasia/parser\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/language.py:1170\u001b[0m, in \u001b[0;36mLanguage.update\u001b[0;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[39mfor\u001b[39;00m name, proc \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline:\n\u001b[1;32m   1168\u001b[0m     \u001b[39m# ignore statements are used here because mypy ignores hasattr\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1170\u001b[0m         proc\u001b[39m.\u001b[39;49mupdate(examples, sgd\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, losses\u001b[39m=\u001b[39;49mlosses, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg[name])  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m     \u001b[39mif\u001b[39;00m sgd \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1172\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1173\u001b[0m             name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude\n\u001b[1;32m   1174\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(proc, ty\u001b[39m.\u001b[39mTrainableComponent)\n\u001b[1;32m   1175\u001b[0m             \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mis_trainable\n\u001b[1;32m   1176\u001b[0m             \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mmodel \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1177\u001b[0m         ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/pipeline/transition_parser.pyx:413\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.update\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/pipeline/transition_parser.pyx:525\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.get_batch_loss\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/pipeline/_parser_internals/arc_eager.pyx:828\u001b[0m, in \u001b[0;36mspacy.pipeline._parser_internals.arc_eager.ArcEager.set_costs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E1031] Could not find gold transition - see logs above."
     ]
    }
   ],
   "source": [
    "from spacy.pipeline import EntityRecognizer\n",
    "nlp = sp.blank('ru')\n",
    "\n",
    "parser = nlp.create_pipe(\"parser\")\n",
    "nlp.add_pipe(\"parser\", first=True)\n",
    "\n",
    "for text, annotations in TRAINING_DATA:\n",
    "    for d in annotations.get('deps', []):\n",
    "        parser.add_label(d)\n",
    "\n",
    "optimizer = nlp.begin_training() \n",
    "\n",
    "import random\n",
    "for i in range(2):\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    nlp.update(ex, sgd=optimizer)\n",
    "parser.to_disk('/Users/anastasia/parser')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
